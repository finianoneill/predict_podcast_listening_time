{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "\n",
    "* Author: Finian O'Neill\n",
    "* Purpose: Conduct the feature engineering on the training dataset. Then, create a ML pipeline to train a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_similar_categories(df, column_name, n_clusters=None, similarity_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Groups semantically similar categories using text similarity and clustering\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        The input dataframe\n",
    "    column_name : str\n",
    "        Name of the categorical column to process\n",
    "    n_clusters : int, optional\n",
    "        Number of clusters to create. If None, determined automatically\n",
    "    similarity_threshold : float, optional\n",
    "        Threshold for considering categories similar in automatic mode\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df_copy : pandas DataFrame\n",
    "        DataFrame with the new clustered column\n",
    "    mapping : dict\n",
    "        Mapping from original categories to cluster labels\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Get unique categories\n",
    "    categories = df[column_name].dropna().unique().tolist()\n",
    "    \n",
    "    # If very few categories, no need to cluster\n",
    "    if len(categories) <= 5:\n",
    "        print(f\"Only {len(categories)} categories found. No clustering needed.\")\n",
    "        return df_copy, {cat: cat for cat in categories}\n",
    "    \n",
    "    # Convert categories to strings\n",
    "    categories = [str(cat) for cat in categories]\n",
    "    \n",
    "    # Create TF-IDF vectors for the categories\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(categories)\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Determine number of clusters if not provided\n",
    "    if n_clusters is None:\n",
    "        # Use elbow method or silhouette score\n",
    "        distortions = []\n",
    "        K_range = range(1, min(15, len(categories)))\n",
    "        for k in K_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(tfidf_matrix)\n",
    "            distortions.append(kmeans.inertia_)\n",
    "        \n",
    "        # Find \"elbow\" point - simple heuristic\n",
    "        deltas = np.diff(distortions)\n",
    "        n_clusters = np.argmax(deltas) + 1\n",
    "        n_clusters = max(n_clusters, 2)  # At least 2 clusters\n",
    "        \n",
    "        # Plot elbow curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(K_range, distortions, 'bx-')\n",
    "        plt.xlabel('Number of clusters')\n",
    "        plt.ylabel('Distortion')\n",
    "        plt.title('Elbow Method For Optimal Clusters')\n",
    "        plt.axvline(x=n_clusters, color='r', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Auto-selected {n_clusters} clusters based on elbow method\")\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "    \n",
    "    # Create mapping from original categories to cluster labels\n",
    "    mapping = {}\n",
    "    cluster_groups = defaultdict(list)\n",
    "    \n",
    "    for cat, label in zip(categories, cluster_labels):\n",
    "        cluster_groups[label].append(cat)\n",
    "    \n",
    "    # Create meaningful names for clusters\n",
    "    for label, members in cluster_groups.items():\n",
    "        if len(members) == 1:\n",
    "            # If only one member, keep original name\n",
    "            cluster_name = members[0]\n",
    "        else:\n",
    "            # Find most frequent or representative member\n",
    "            counts = df[df[column_name].isin(members)][column_name].value_counts()\n",
    "            most_common = counts.index[0] if not counts.empty else members[0]\n",
    "            cluster_name = f\"{most_common}_cluster_{label}\"\n",
    "        \n",
    "        # Map all members to this cluster name\n",
    "        for member in members:\n",
    "            mapping[member] = cluster_name\n",
    "    \n",
    "    # Apply mapping to create new column\n",
    "    new_col_name = f\"{column_name}_clustered\"\n",
    "    df_copy[new_col_name] = df_copy[column_name].astype(str).map(mapping)\n",
    "    df_copy[new_col_name] = df_copy[new_col_name].fillna('other')\n",
    "    \n",
    "    # Print cluster statistics\n",
    "    original_count = len(categories)\n",
    "    new_count = len(set(mapping.values()))\n",
    "    print(f\"Reduced cardinality from {original_count} to {new_count} categories\")\n",
    "    \n",
    "    # Print samples from each cluster to verify semantic similarity\n",
    "    print(\"\\nSample clusters:\")\n",
    "    for label, members in list(cluster_groups.items())[:5]:  # Show first 5 clusters\n",
    "        print(f\"Cluster {label}: {', '.join(members[:5])}\" + \n",
    "              (f\" ... and {len(members)-5} more\" if len(members) > 5 else \"\"))\n",
    "    \n",
    "    return df_copy, mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset and expect\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-playground",
   "language": "python",
   "name": "kaggle-playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
